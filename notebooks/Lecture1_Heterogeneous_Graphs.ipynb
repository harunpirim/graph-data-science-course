{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20544f87",
   "metadata": {},
   "source": [
    "# Lecture 1: Heterogeneous Graphs & Typed Message Passing (PyTorch Geometric)\n",
    "\n",
    "This notebook is designed for a graduate-level Graph ML course.\n",
    "\n",
    "**Learning goals**\n",
    "\n",
    "By the end of this notebook, you should be able to:\n",
    "\n",
    "- Model real systems as heterogeneous graphs from a network science perspective.\n",
    "- Understand the formal definition of a heterogeneous graph.\n",
    "- Implement a toy heterogeneous academic graph using `torch_geometric.data.HeteroData`.\n",
    "- Train a simple heterogeneous GNN for paper node classification using `to_hetero`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff228834",
   "metadata": {},
   "source": [
    "## 1. Heterogeneous Graphs: Intuition & Definition\n",
    "\n",
    "In many network science examples, we model a system as a *homogeneous* graph:\n",
    "\n",
    "- One node type (e.g., \"person\")\n",
    "- One edge type (e.g., \"friendship\")\n",
    "\n",
    "But real systems are often richer:\n",
    "\n",
    "- Academic network: **authors – papers – institutions – fields**\n",
    "- E-commerce: **users – items – categories**\n",
    "- Biology: **genes – proteins – diseases – drugs**\n",
    "\n",
    "A **heterogeneous graph** (a.k.a. *heterogeneous information network*) is:\n",
    "\n",
    "\\begin{equation}\n",
    "G = (V, E, \\phi, \\psi)\n",
    "\\end{equation}\n",
    "\n",
    "- \\(V\\): set of nodes\n",
    "- \\(E\\): set of edges\n",
    "- \\(\\phi: V \\rightarrow \\mathcal{T}_V\\): node type mapping\n",
    "- \\(\\psi: E \\rightarrow \\mathcal{T}_E\\): edge (relation) type mapping\n",
    "\n",
    "Here, \\(\\mathcal{T}_V\\) is the set of node types and \\(\\mathcal{T}_E\\) is the set of edge types.\n",
    "\n",
    "You can think of each relation type as a different **layer** in a multilayer network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d3404d",
   "metadata": {},
   "source": [
    "### Typed Message Passing\n",
    "\n",
    "In a standard (homogeneous) GNN layer we have:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{h}_i^{(l+1)} = \\sigma\\left( \\sum_{j \\in \\mathcal{N}(i)} \\frac{1}{c_{ij}} W^{(l)} \\mathbf{h}_j^{(l)} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "For a **heterogeneous** graph, neighbors come via *different* relation types. For each relation \\(r \\in \\mathcal{T}_E\\) we use a relation-specific weight matrix \\(W_r^{(l)}\\):\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{h}_i^{(l+1)} = \\sigma\\left(\n",
    "    \\sum_{r \\in \\mathcal{T}_E}\n",
    "    \\sum_{j \\in \\mathcal{N}_r(i)}\n",
    "    \\frac{1}{c_{ijr}} W_r^{(l)} \\mathbf{h}_j^{(l)}\n",
    "\\right).\n",
    "\\end{equation}\n",
    "\n",
    "- \\(\\mathcal{N}_r(i)\\): neighbors of node \\(i\\) through relation \\(r\\)\n",
    "- Each relation is a \"channel\" of information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540ae25e",
   "metadata": {},
   "source": [
    "## 2. Setup\n",
    "\n",
    "Install and import dependencies. In a fresh environment you may need to install `torch` and `torch-geometric` following the official instructions.\n",
    "\n",
    "> **Note:** The installation commands are commented out; uncomment and adapt them as needed in your own environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ff5d3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install torch torch_geometric -q\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0996cdb",
   "metadata": {},
   "source": [
    "## 3. Build a Toy Academic Heterogeneous Graph\n",
    "\n",
    "We will build a small academic-style network with three node types:\n",
    "\n",
    "- `author`\n",
    "- `paper`\n",
    "- `institution`\n",
    "\n",
    "Edges will include:\n",
    "\n",
    "- `author` —**writes**→ `paper`\n",
    "- `paper` —**written_by**→ `author` (reverse)\n",
    "- `author` —**affiliated_with**→ `institution`\n",
    "- `institution` —**has_member**→ `author` (reverse)\n",
    "- `paper` —**cites**→ `paper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d8ecafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  author={ x=[100, 16] },\n",
       "  paper={ x=[200, 16] },\n",
       "  institution={ x=[10, 16] },\n",
       "  (author, writes, paper)={ edge_index=[2, 400] },\n",
       "  (paper, written_by, author)={ edge_index=[2, 400] },\n",
       "  (author, affiliated_with, institution)={ edge_index=[2, 100] },\n",
       "  (institution, has_member, author)={ edge_index=[2, 100] },\n",
       "  (paper, cites, paper)={ edge_index=[2, 500] }\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a HeteroData object\n",
    "data = HeteroData()\n",
    "\n",
    "# Define sizes\n",
    "num_authors = 100\n",
    "num_papers = 200\n",
    "num_institutions = 10\n",
    "\n",
    "# Node features (16-dim for each type)\n",
    "data['author'].x = torch.randn(num_authors, 16)\n",
    "data['paper'].x = torch.randn(num_papers, 16)\n",
    "data['institution'].x = torch.randn(num_institutions, 16)\n",
    "\n",
    "# Edges: author -> paper (writes)\n",
    "num_auth_paper_edges = 400\n",
    "author_ids = torch.randint(0, num_authors, (num_auth_paper_edges,))\n",
    "paper_ids  = torch.randint(0, num_papers, (num_auth_paper_edges,))\n",
    "data[('author', 'writes', 'paper')].edge_index = torch.stack([author_ids, paper_ids], dim=0)\n",
    "\n",
    "# Reverse edges: paper -> author (written_by)\n",
    "data[('paper', 'written_by', 'author')].edge_index = torch.stack([paper_ids, author_ids], dim=0)\n",
    "\n",
    "# Edges: author -> institution (affiliated_with)\n",
    "num_auth_inst_edges = num_authors  # one institution per author for simplicity\n",
    "author_ids2 = torch.arange(num_authors)\n",
    "inst_ids = torch.randint(0, num_institutions, (num_authors,))\n",
    "data[('author', 'affiliated_with', 'institution')].edge_index = torch.stack([author_ids2, inst_ids], dim=0)\n",
    "\n",
    "# Reverse edges: institution -> author (has_member)\n",
    "data[('institution', 'has_member', 'author')].edge_index = torch.stack([inst_ids, author_ids2], dim=0)\n",
    "\n",
    "# Edges: paper -> paper (cites)\n",
    "num_citations = 500\n",
    "src_papers = torch.randint(0, num_papers, (num_citations,))\n",
    "dst_papers = torch.randint(0, num_papers, (num_citations,))\n",
    "data[('paper', 'cites', 'paper')].edge_index = torch.stack([src_papers, dst_papers], dim=0)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2151cb14",
   "metadata": {},
   "source": [
    "### Create a Paper Classification Task\n",
    "\n",
    "We assign each paper a label from 0 to 3 (simulating 4 research fields) and create train/val/test masks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20534321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  author={ x=[100, 16] },\n",
       "  paper={\n",
       "    x=[200, 16],\n",
       "    y=[200],\n",
       "    train_mask=[200],\n",
       "    val_mask=[200],\n",
       "    test_mask=[200],\n",
       "  },\n",
       "  institution={ x=[10, 16] },\n",
       "  (author, writes, paper)={ edge_index=[2, 400] },\n",
       "  (paper, written_by, author)={ edge_index=[2, 400] },\n",
       "  (author, affiliated_with, institution)={ edge_index=[2, 100] },\n",
       "  (institution, has_member, author)={ edge_index=[2, 100] },\n",
       "  (paper, cites, paper)={ edge_index=[2, 500] }\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 4\n",
    "num_papers = data['paper'].x.size(0)\n",
    "\n",
    "# Random labels for papers\n",
    "data['paper'].y = torch.randint(0, num_classes, (num_papers,))\n",
    "\n",
    "# Train/val/test masks for papers\n",
    "train_ratio, val_ratio = 0.6, 0.2\n",
    "perm = torch.randperm(num_papers)\n",
    "train_end = int(train_ratio * num_papers)\n",
    "val_end = int((train_ratio + val_ratio) * num_papers)\n",
    "\n",
    "train_mask = torch.zeros(num_papers, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_papers, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_papers, dtype=torch.bool)\n",
    "\n",
    "train_mask[perm[:train_end]] = True\n",
    "val_mask[perm[train_end:val_end]] = True\n",
    "test_mask[perm[val_end:]] = True\n",
    "\n",
    "data['paper'].train_mask = train_mask\n",
    "data['paper'].val_mask = val_mask\n",
    "data['paper'].test_mask = test_mask\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6abc0",
   "metadata": {},
   "source": [
    "## 4. Define a Base GNN and Convert with `to_hetero`\n",
    "\n",
    "We first define a standard GraphSAGE-style GNN that works on a homogeneous graph. Then we use `to_hetero` so PyG automatically creates relation-specific copies for each edge type.\n",
    "\n",
    "Mathematically, this corresponds to:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{h}_i^{(l+1)} = \\sigma\\left(\n",
    "    \\sum_{r \\in \\mathcal{T}_E}\n",
    "    \\sum_{j \\in \\mathcal{N}_r(i)}\n",
    "    \\frac{1}{c_{ijr}} W_r^{(l)} \\mathbf{h}_j^{(l)}\n",
    "\\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5aa0657",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.fx._symbolic_trace' has no attribute 'List'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m BaseGNN(hidden_channels, num_classes)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Convert to heterogeneous model\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m hetero_model \u001b[38;5;241m=\u001b[39m \u001b[43mto_hetero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m hetero_model \u001b[38;5;241m=\u001b[39m hetero_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     26\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/python_venv/lib/python3.12/site-packages/torch_geometric/nn/to_hetero_transformer.py:119\u001b[0m, in \u001b[0;36mto_hetero\u001b[0;34m(module, metadata, aggr, input_map, debug)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_hetero\u001b[39m(module: Module, metadata: Metadata, aggr: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m               input_map: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     29\u001b[0m               debug: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GraphModule:\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Converts a homogeneous GNN model into its heterogeneous equivalent in\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    which node representations are learned for each node type in\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    :obj:`metadata[0]`, and messages are exchanged between each edge type in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m            transformation in debug mode. (default: :obj:`False`)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     transformer \u001b[38;5;241m=\u001b[39m \u001b[43mToHeteroTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transformer\u001b[38;5;241m.\u001b[39mtransform()\n",
      "File \u001b[0;32m~/python_venv/lib/python3.12/site-packages/torch_geometric/nn/to_hetero_transformer.py:143\u001b[0m, in \u001b[0;36mToHeteroTransformer.__init__\u001b[0;34m(self, module, metadata, aggr, input_map, debug)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    137\u001b[0m     module: Module,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     debug: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m ):\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m metadata\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggr \u001b[38;5;241m=\u001b[39m aggr\n",
      "File \u001b[0;32m~/python_venv/lib/python3.12/site-packages/torch_geometric/nn/fx.py:74\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[0;34m(self, module, input_map, debug)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     69\u001b[0m     module: Module,\n\u001b[1;32m     70\u001b[0m     input_map: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m     debug: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m ):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgm \u001b[38;5;241m=\u001b[39m \u001b[43msymbolic_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_map \u001b[38;5;241m=\u001b[39m input_map\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m=\u001b[39m debug\n",
      "File \u001b[0;32m~/python_venv/lib/python3.12/site-packages/torch_geometric/nn/fx.py:375\u001b[0m, in \u001b[0;36msymbolic_trace\u001b[0;34m(module, concrete_args)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmodule_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\n\u001b[0;32m--> 375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GraphModule(module, \u001b[43mTracer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_args\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/python_venv/lib/python3.12/site-packages/torch_geometric/nn/fx.py:314\u001b[0m, in \u001b[0;36msymbolic_trace.<locals>.Tracer.trace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m Graph(tracer_cls\u001b[38;5;241m=\u001b[39mtracer_cls)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor_attrs: Dict[st\u001b[38;5;241m.\u001b[39mUnion[torch\u001b[38;5;241m.\u001b[39mTensor, st\u001b[38;5;241m.\u001b[39mScriptObject],\n\u001b[1;32m    311\u001b[0m                         \u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcollect_tensor_attrs\u001b[39m(m: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[0;32m--> 314\u001b[0m                          prefix_atoms: \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mList\u001b[49m[\u001b[38;5;28mstr\u001b[39m]):\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (torch\u001b[38;5;241m.\u001b[39mTensor, st\u001b[38;5;241m.\u001b[39mScriptObject)):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.fx._symbolic_trace' has no attribute 'List'"
     ]
    }
   ],
   "source": [
    "class BaseGNN(nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        # (-1, -1) lets PyG infer input dims for each node type\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.lin = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x: node features (for a single meta-type)\n",
    "        # edge_index: adjacency\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        return self.lin(x)\n",
    "\n",
    "\n",
    "metadata = data.metadata()  # (node_types, edge_types)\n",
    "hidden_channels = 32\n",
    "model = BaseGNN(hidden_channels, num_classes)\n",
    "\n",
    "# Convert to heterogeneous model\n",
    "hetero_model = to_hetero(model, metadata, aggr='sum')\n",
    "hetero_model = hetero_model.to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "hetero_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84594845",
   "metadata": {},
   "source": [
    "## 5. Train the Heterogeneous GNN for Paper Classification\n",
    "\n",
    "We now train the model using cross-entropy loss on the `paper` node type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(hetero_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    hetero_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out_dict = hetero_model(data.x_dict, data.edge_index_dict)\n",
    "    out = out_dict['paper']  # logits for paper nodes\n",
    "\n",
    "    loss = criterion(out[data['paper'].train_mask],\n",
    "                     data['paper'].y[data['paper'].train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(split='val'):\n",
    "    hetero_model.eval()\n",
    "    out_dict = hetero_model(data.x_dict, data.edge_index_dict)\n",
    "    out = out_dict['paper'].softmax(dim=-1)\n",
    "    y_true = data['paper'].y\n",
    "\n",
    "    if split == 'train':\n",
    "        mask = data['paper'].train_mask\n",
    "    elif split == 'val':\n",
    "        mask = data['paper'].val_mask\n",
    "    else:\n",
    "        mask = data['paper'].test_mask\n",
    "\n",
    "    pred = out[mask].argmax(dim=-1)\n",
    "    correct = (pred == y_true[mask]).sum().item()\n",
    "    total = mask.sum().item()\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        train_acc = evaluate('train')\n",
    "        val_acc = evaluate('val')\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.3f}, Val Acc: {val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54149443",
   "metadata": {},
   "source": [
    "## 6. Discussion & Exercises\n",
    "\n",
    "**Questions / prompts:**\n",
    "\n",
    "1. Network science view: Interpret each edge type as a *layer* of a multiplex network. How is the GNN aggregating across layers?\n",
    "2. What happens if you drop the `cites` relation? Does validation accuracy change?\n",
    "3. Try modifying the model to use `aggr='mean'` instead of `sum`. Does it matter on this toy data?\n",
    "\n",
    "**Extensions:**\n",
    "\n",
    "- Add a new node type `field` and connect papers to fields (topics).\n",
    "- Visualize the degree distributions for each node type and compare with classical measures like degree centrality.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
