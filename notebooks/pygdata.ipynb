{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd212b8",
   "metadata": {},
   "source": [
    "# Preparing your data to work with PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e04b338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harunpirim/Documents/GitHub/graphdataA.github.io/graph-data-science-course/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf37e2d",
   "metadata": {},
   "source": [
    "## NX Social Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7196577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 5\n",
      "Number of edges: 6\n",
      "Nodes: ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve']\n",
      "Edges: [('Alice', 'Bob'), ('Alice', 'Charlie'), ('Bob', 'Charlie'), ('Bob', 'Diana'), ('Charlie', 'Eve'), ('Diana', 'Eve')]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a simple social graph\n",
    "social_graph = nx.Graph()\n",
    "\n",
    "# Add nodes (people)\n",
    "social_graph.add_nodes_from(['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'])\n",
    "\n",
    "# Add edges (friendships)\n",
    "social_graph.add_edge('Alice', 'Bob')\n",
    "social_graph.add_edge('Alice', 'Charlie')\n",
    "social_graph.add_edge('Bob', 'Charlie')\n",
    "social_graph.add_edge('Bob', 'Diana')\n",
    "social_graph.add_edge('Charlie', 'Eve')\n",
    "social_graph.add_edge('Diana', 'Eve')\n",
    "\n",
    "print(f\"Number of nodes: {social_graph.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {social_graph.number_of_edges()}\")\n",
    "print(f\"Nodes: {list(social_graph.nodes())}\")\n",
    "print(f\"Edges: {list(social_graph.edges())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beee835b",
   "metadata": {},
   "source": [
    "## From NX object to PyG object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eae1cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 12], num_nodes=5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = utils.from_networkx(social_graph)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c117c2",
   "metadata": {},
   "source": [
    "## From raw data to PyG object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab646e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 7 nodes and 10 edges\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "{'Bob': 0, 'Eve': 1, 'Charlie': 2, 'Diana': 3, 'Frank': 4, 'Alice': 5, 'Gina': 6}\n",
      "{0: 'Bob', 1: 'Eve', 2: 'Charlie', 3: 'Diana', 4: 'Frank', 5: 'Alice', 6: 'Gina'}\n"
     ]
    }
   ],
   "source": [
    "social_graph = nx.read_edgelist('edge_list2.txt')\n",
    "print(social_graph)\n",
    "list_of_nodes = list(set(list(social_graph)))\n",
    "indices_of_nodes = [list_of_nodes.index(x)\\\n",
    " for x in list_of_nodes]\n",
    "print(indices_of_nodes)\n",
    "node_to_index = dict(zip(list_of_nodes, indices_of_nodes))\n",
    "index_to_node = dict(zip(indices_of_nodes, list_of_nodes))\n",
    "print(node_to_index)\n",
    "print(index_to_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "696c75bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, 0, 0, 0, 2, 3, 3, 1]\n",
      "[0, 2, 4, 2, 3, 4, 1, 1, 6, 6]\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([1, 1, 1, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "list_edges = nx.convert.to_edgelist(social_graph)\n",
    "list_edges = list(list_edges)\n",
    "named_edge_list_0 = [x[0] for x in list_edges]\n",
    "named_edge_list_1 = [x[1] for x in list_edges]\n",
    "\n",
    "indexed_edge_list_0 = [node_to_index[x]\\\n",
    " for x in named_edge_list_0]\n",
    "indexed_edge_list_1 = [node_to_index[x] for x in named_edge_list_1]\n",
    "print(indexed_edge_list_0)\n",
    "print(indexed_edge_list_1)\n",
    "x = torch.FloatTensor([[1] for x in range(len(list_of_nodes))])\n",
    "# Create labels for binary classification: 4 nodes labeled as 1, 3 nodes labeled as 0\n",
    "y = torch.FloatTensor([1]*4 + [0]*3)\n",
    "y = y.long()\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d28849c",
   "metadata": {},
   "source": [
    "Prepare for training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5a08b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[7, 1], edge_index=[2, 10], y=[7], train_mask=[7], test_mask=[7])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([1, 1, 1, 1, 0, 0, 0])\n",
      "tensor([[5, 5, 5, 0, 0, 0, 2, 3, 3, 1],\n",
      "        [0, 2, 4, 2, 3, 4, 1, 1, 6, 6]])\n",
      "tensor([ True,  True,  True,  True,  True, False, False])\n",
      "tensor([False, False, False, False, False,  True,  True])\n",
      "\n",
      "Train nodes: 5, Test nodes: 2\n",
      "Masks are complementary: True\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([indexed_edge_list_0,\\\n",
    " indexed_edge_list_1])\n",
    "\n",
    "# Calculate train size (80% of nodes)\n",
    "train_size = int(0.8 * len(list_of_nodes))\n",
    "# Test size is the remainder to ensure complementary masks\n",
    "test_size = len(list_of_nodes) - train_size\n",
    "\n",
    "train_mask = torch.zeros(len(list_of_nodes), dtype=torch.bool)\n",
    "train_mask[:train_size] = True  # First 80% for training\n",
    "\n",
    "test_mask = torch.zeros(len(list_of_nodes), dtype=torch.bool)\n",
    "test_mask[train_size:] = True  # Remaining 20% for testing\n",
    "\n",
    "data = Data(x=x, y=y, edge_index=edge_index,\\\n",
    " train_mask=train_mask, test_mask=test_mask)\n",
    "print(data)\n",
    "print(data.x)\n",
    "print(data.y)\n",
    "print(data.edge_index)\n",
    "print(data.train_mask)\n",
    "print(data.test_mask)\n",
    "print(f\"\\nTrain nodes: {train_mask.sum().item()}, Test nodes: {test_mask.sum().item()}\")\n",
    "print(f\"Masks are complementary: {(train_mask & test_mask).sum().item() == 0}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b15e0d4",
   "metadata": {},
   "source": [
    "## Link Prediction with Train/Test Masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c9ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "# For link prediction, we need to split edges (not nodes) into train/test\n",
    "# Get all edges from the graph\n",
    "num_edges = data.edge_index.size(1)\n",
    "print(f\"Total edges in graph: {num_edges}\")\n",
    "\n",
    "# Split edges into train (80%) and test (20%)\n",
    "num_train_edges = int(0.8 * num_edges)\n",
    "num_test_edges = num_edges - num_train_edges\n",
    "\n",
    "# Shuffle edge indices\n",
    "edge_indices = torch.randperm(num_edges)\n",
    "\n",
    "# Split into train and test edge indices\n",
    "train_edge_indices = edge_indices[:num_train_edges]\n",
    "test_edge_indices = edge_indices[num_train_edges:]\n",
    "\n",
    "# Create train and test edge sets\n",
    "train_edges = data.edge_index[:, train_edge_indices]\n",
    "test_edges = data.edge_index[:, test_edge_indices]\n",
    "\n",
    "print(f\"\\nTrain edges: {train_edges.size(1)}\")\n",
    "print(f\"Test edges: {test_edges.size(1)}\")\n",
    "\n",
    "# Create positive edge labels (1 for existing edges)\n",
    "train_pos_labels = torch.ones(train_edges.size(1), dtype=torch.long)\n",
    "test_pos_labels = torch.ones(test_edges.size(1), dtype=torch.long)\n",
    "\n",
    "# Generate negative edges (non-existent edges) for training and testing\n",
    "# Negative sampling ensures we don't sample edges that already exist\n",
    "train_neg_edges = negative_sampling(\n",
    "    edge_index=train_edges,\n",
    "    num_nodes=data.num_nodes,\n",
    "    num_neg_samples=train_edges.size(1)  # Same number as positive edges\n",
    ")\n",
    "\n",
    "test_neg_edges = negative_sampling(\n",
    "    edge_index=data.edge_index,  # Use full graph to avoid sampling test edges\n",
    "    num_nodes=data.num_nodes,\n",
    "    num_neg_samples=test_edges.size(1)  # Same number as positive edges\n",
    ")\n",
    "\n",
    "# Create negative edge labels (0 for non-existing edges)\n",
    "train_neg_labels = torch.zeros(train_neg_edges.size(1), dtype=torch.long)\n",
    "test_neg_labels = torch.zeros(test_neg_edges.size(1), dtype=torch.long)\n",
    "\n",
    "# Combine positive and negative edges for training\n",
    "train_edge_label_index = torch.cat([train_edges, train_neg_edges], dim=1)\n",
    "train_edge_label = torch.cat([train_pos_labels, train_neg_labels], dim=0)\n",
    "\n",
    "# Combine positive and negative edges for testing\n",
    "test_edge_label_index = torch.cat([test_edges, test_neg_edges], dim=1)\n",
    "test_edge_label = torch.cat([test_pos_labels, test_neg_labels], dim=0)\n",
    "\n",
    "# Create masks for link prediction\n",
    "# For link prediction, we use edge_label_index and edge_label instead of node masks\n",
    "link_data = Data(\n",
    "    x=data.x,\n",
    "    edge_index=train_edges,  # Only training edges are visible during training\n",
    "    train_edge_label_index=train_edge_label_index,\n",
    "    train_edge_label=train_edge_label,\n",
    "    test_edge_label_index=test_edge_label_index,\n",
    "    test_edge_label=test_edge_label\n",
    ")\n",
    "\n",
    "print(f\"\\nLink Prediction Data:\")\n",
    "print(f\"  Node features: {link_data.x.shape}\")\n",
    "print(f\"  Training edges (visible): {link_data.edge_index.shape[1]}\")\n",
    "print(f\"  Train edge pairs (pos + neg): {link_data.train_edge_label_index.shape[1]}\")\n",
    "print(f\"  Test edge pairs (pos + neg): {link_data.test_edge_label_index.shape[1]}\")\n",
    "print(f\"\\nTrain positive edges: {train_pos_labels.sum().item()}\")\n",
    "print(f\"Train negative edges: {train_neg_labels.sum().item()}\")\n",
    "print(f\"Test positive edges: {test_pos_labels.sum().item()}\")\n",
    "print(f\"Test negative edges: {test_neg_labels.sum().item()}\")\n",
    "\n",
    "# Display some examples\n",
    "print(f\"\\nExample train positive edges (first 3):\")\n",
    "print(train_edges[:, :3].t())\n",
    "print(f\"\\nExample train negative edges (first 3):\")\n",
    "print(train_neg_edges[:, :3].t())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a0d8b3",
   "metadata": {},
   "source": [
    "### Using Link Prediction Data\n",
    "\n",
    "The `link_data` object now contains:\n",
    "- `edge_index`: Only training edges (visible during training)\n",
    "- `train_edge_label_index`: Edge pairs to predict during training (pos + neg)\n",
    "- `train_edge_label`: Labels for training edges (1=exists, 0=doesn't exist)\n",
    "- `test_edge_label_index`: Edge pairs to predict during testing (pos + neg)\n",
    "- `test_edge_label`: Labels for test edges (1=exists, 0=doesn't exist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22eca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Simple link prediction model structure\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Simple link prediction model:\n",
    "    1. GCN encoder to get node embeddings\n",
    "    2. Dot product decoder to predict edge existence\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "    \n",
    "    def encode(self, x, edge_index):\n",
    "        \"\"\"Encode nodes into embeddings\"\"\"\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, z, edge_label_index):\n",
    "        \"\"\"Predict edge existence from node embeddings\"\"\"\n",
    "        # Get embeddings for source and target nodes\n",
    "        src = z[edge_label_index[0]]\n",
    "        dst = z[edge_label_index[1]]\n",
    "        # Dot product as edge score\n",
    "        return (src * dst).sum(dim=1)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_label_index):\n",
    "        z = self.encode(x, edge_index)\n",
    "        return self.decode(z, edge_label_index)\n",
    "\n",
    "# Initialize model\n",
    "model = LinkPredictor(in_channels=1, hidden_channels=16, out_channels=8)\n",
    "print(\"Link Prediction Model:\")\n",
    "print(model)\n",
    "\n",
    "# Example forward pass for training\n",
    "train_pred = model(link_data.x, link_data.edge_index, link_data.train_edge_label_index)\n",
    "print(f\"\\nTraining predictions shape: {train_pred.shape}\")\n",
    "print(f\"Training labels shape: {link_data.train_edge_label.shape}\")\n",
    "\n",
    "# Example forward pass for testing\n",
    "test_pred = model(link_data.x, link_data.edge_index, link_data.test_edge_label_index)\n",
    "print(f\"Test predictions shape: {test_pred.shape}\")\n",
    "print(f\"Test labels shape: {link_data.test_edge_label.shape}\")\n",
    "\n",
    "# Example loss calculation (binary cross entropy)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "train_loss = criterion(train_pred, link_data.train_edge_label.float())\n",
    "print(f\"\\nExample training loss: {train_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890ec6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
