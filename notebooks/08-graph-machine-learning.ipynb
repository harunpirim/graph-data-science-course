{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Machine Learning\n",
    "\n",
    "This notebook demonstrates Graph Machine Learning techniques using PyTorch Geometric.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand Graph Neural Networks (GNNs)\n",
    "- Implement node classification\n",
    "- Perform link prediction\n",
    "- Apply graph classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install torch torch-geometric torch-scatter torch-sparse\n",
    "\n",
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.datasets import Planetoid, KarateClub\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Graph Neural Networks\n",
    "\n",
    "Let's start with a simple GNN implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple GCN implementation\n",
    "class SimpleGCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(SimpleGCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # First GCN layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        # Second GCN layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "print(\"Simple GCN model created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Node Classification\n",
    "\n",
    "Let's implement node classification using the Cora dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Cora dataset\n",
    "try:\n",
    "    dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "    data = dataset[0]\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    print(f\"Number of graphs: {len(dataset)}\")\n",
    "    print(f\"Number of features: {dataset.num_features}\")\n",
    "    print(f\"Number of classes: {dataset.num_classes}\")\n",
    "    print(f\"Number of nodes: {data.num_nodes}\")\n",
    "    print(f\"Number of edges: {data.num_edges}\")\n",
    "    print(f\"Average node degree: {data.num_edges / data.num_nodes:.2f}\")\n",
    "    print(f\"Number of training nodes: {data.train_mask.sum()}\")\n",
    "    print(f\"Number of validation nodes: {data.val_mask.sum()}\")\n",
    "    print(f\"Number of test nodes: {data.test_mask.sum()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Cora dataset: {e}\")\n",
    "    print(\"Creating a simple synthetic dataset instead...\")\n",
    "    \n",
    "    # Create synthetic data\n",
    "    num_nodes = 100\n",
    "    num_features = 16\n",
    "    num_classes = 7\n",
    "    \n",
    "    # Random features\n",
    "    x = torch.randn(num_nodes, num_features)\n",
    "    \n",
    "    # Random edges\n",
    "    edge_index = torch.randint(0, num_nodes, (2, 200))\n",
    "    \n",
    "    # Random labels\n",
    "    y = torch.randint(0, num_classes, (num_nodes,))\n",
    "    \n",
    "    # Create masks\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    train_mask[:70] = True\n",
    "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask[70:85] = True\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask[85:] = True\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index, y=y, \n",
    "               train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n",
    "    \n",
    "    print(f\"Synthetic dataset created with {num_nodes} nodes and {num_classes} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the GCN model\n",
    "def train_gcn(data, epochs=200):\n",
    "    model = SimpleGCN(data.num_features, data.y.max().item() + 1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    \n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print(f'Epoch {epoch:03d}: Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return model, losses\n",
    "\n",
    "# Train the model\n",
    "model, losses = train_gcn(data)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_acc = pred[data.train_mask].eq(data.y[data.train_mask]).sum().item() / data.train_mask.sum().item()\n",
    "    val_acc = pred[data.val_mask].eq(data.y[data.val_mask]).sum().item() / data.val_mask.sum().item()\n",
    "    test_acc = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n",
    "    \n",
    "    print(f'Train Accuracy: {train_acc:.4f}')\n",
    "    print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph Attention Networks (GAT)\n",
    "\n",
    "Let's implement a Graph Attention Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT implementation\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes, num_heads=8):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_features, 8, heads=num_heads, dropout=0.6)\n",
    "        self.conv2 = GATConv(8 * num_heads, num_classes, heads=1, concat=False, dropout=0.6)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "print(\"GAT model created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary and Key Insights\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Graph Neural Networks**: Extend neural networks to graph-structured data\n",
    "2. **Message Passing**: Nodes aggregate information from their neighbors\n",
    "3. **Attention Mechanisms**: GAT uses attention to weight neighbor importance\n",
    "4. **Node Classification**: Predict node labels using graph structure and features\n",
    "\n",
    "### Applications:\n",
    "- **Social Networks**: User classification, recommendation systems\n",
    "- **Biological Networks**: Protein function prediction, drug discovery\n",
    "- **Knowledge Graphs**: Entity classification, relation extraction\n",
    "- **Computer Vision**: Scene understanding, object detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}